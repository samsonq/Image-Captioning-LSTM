{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "import pkbar\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from model import LSTM\n",
    "import dataset_factory\n",
    "import coco_dataset\n",
    "import vocab\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "f = open(\"./default.json\")\n",
    "\n",
    "config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_wrapper = vocab.Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train_obj = coco_dataset.CocoDataset(config[\"dataset\"][\"images_root_dir\"], \n",
    "                                          config[\"dataset\"][\"training_annotation_file_path\"],\n",
    "                                          config[\"dataset\"][\"training_ids_file_path\"],\n",
    "                                          vocab_wrapper,\n",
    "                                          config[\"dataset\"][\"img_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.81s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.61s)\n",
      "creating index...\n",
      "index created!\n",
      "Using the saved vocab.\n",
      "loading annotations into memory...\n",
      "Done (t=0.86s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.91s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_test, vocabulary, train_data_loader, val_data_loader, test_data_loader = dataset_factory.get_datasets(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=config[\"experiment\"][\"num_epochs\"]):\n",
    "    # Bar to keep train of training time\n",
    "    bar = pkbar.Pbar(name=\"Training in progress.\", target=epochs)\n",
    "    #set model to train mode\n",
    "    model.train()\n",
    "    #vars for storing values to return\n",
    "    best_model = None\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_val_acc = None\n",
    "    #training loop\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        train_correct = 0\n",
    "        val_loss_value = 0\n",
    "        val_correct = 0\n",
    "        for data, labels in train_loader:\n",
    "            #move data to gpu\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            #zero gradient\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass then backprop\n",
    "            y_hat = model(data)\n",
    "            loss = criterion(y_hat, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #tally loss\n",
    "            epoch_loss += loss.item()\n",
    "            #tally correct\n",
    "            _, preds = torch.max(y_hat.data, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "        #get validation acc and loss\n",
    "        #no grad because we don't want to train on it\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for val_data, val_labels in val_loader:\n",
    "                #move data to gpu\n",
    "                val_data, val_labels = val_data.to(device), val_labels.to(device)\n",
    "                #forward pass\n",
    "                val_y_hat = model(val_data)\n",
    "                #tally loss\n",
    "                val_loss = criterion(val_y_hat, val_labels)\n",
    "                val_loss_value += val_loss.item()\n",
    "                #tally correct\n",
    "                _, preds = torch.max(y_hat.data, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "            #deepcopy model with best avg acc on val sets\n",
    "            last_val_acc = val_correct/len(val_loader.dataset)\n",
    "            if best_val_acc is None:\n",
    "                best_val_acc = last_val_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "            elif best_val_acc < last_val_acc:\n",
    "                best_val_acc = last_val_acc\n",
    "                best_model = copy.deepcopy(model)\n",
    "        #record train loss and acc for epoch\n",
    "        train_accs.append(train_correct/len(train_loader.dataset))\n",
    "        train_losses.append(epoch_loss/len(train_loader.dataset))\n",
    "        #append val losses\n",
    "        val_losses.append(val_loss_value/len(val_loader.dataset))\n",
    "        val_accs.append(val_correct/len(val_loader.dataset))\n",
    "        #update loading bar\n",
    "        bar.update(epoch)\n",
    "    return train_losses, val_losses, train_accs, val_accs, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(in_features, config[\"model\"][\"hidden_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet.to(device);\n",
    "\n",
    "for data in tqdm(train_data_loader):\n",
    "    d = data[0].to(device)\n",
    "    resnet(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(config[\"model\"][\"hidden_size\"], config[\"model\"][\"neurons\"], config[\"model\"][\"layers\"])\n",
    "lstm.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        self.encoder = encoder\n",
    "        self.encoder.to(device);\n",
    "\n",
    "        self.decoder = decoder\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.AdamW(self.decoder.parameters(), lr=config[\"experiment\"]['learning_rate'])\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.8, min_lr=config['learning_rate'] * 0.1, verbose=True)\n",
    "\n",
    "        self.decoder.to(device);\n",
    "\n",
    "    def fit(self, x, y, epochs=config[\"experiment\"][\"num_epochs\"]):\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            print(\"Training Epoch {}\".format(epochs + 1))\n",
    "            bar = pkbar.Pbar(name='Training in Process', target=epochs)\n",
    "            \n",
    "            total_loss = 0\n",
    "            best_model = None\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "            train_accs = []\n",
    "            val_accs = []\n",
    "            best_val_acc = None\n",
    "\n",
    "            # Previous validation loss is the smallest loss\n",
    "            prev_val_loss = np.min(validation_losses)\n",
    "            \n",
    "\n",
    "            # Train\n",
    "            model.train()\n",
    "            for i in train_data_loader:\n",
    "                # Set states to 0 at the beginning of each song\n",
    "                hidden_state = torch.zeros((config[\"model\"]['layers'], 1, config[\"model\"]['num_neurons'])).to(device)\n",
    "                hidden_state = hidden_state.float()\n",
    "                cell_state = torch.zeros((config[\"model\"]['layers'], 1, config[\"model\"]['num_neurons'])).to(device)\n",
    "                cell_state = cell_state.float()\n",
    "                hidden = (hidden_state, cell_state)\n",
    "\n",
    "                loss = 0\n",
    "                '''\n",
    "                # Encode the characters to their respective one hot encoding\n",
    "                dataset = MyDataset(song, config['chunk_length'])\n",
    "                num_minibatches = len(dataset)\n",
    "                for i in range(num_minibatches):\n",
    "                    model.zero_grad()\n",
    "                    chunk, targets = dataset[i]\n",
    "\n",
    "                    if len(chunk) == 0:\n",
    "                        break\n",
    "\n",
    "                    # Send minibatch to computing device\n",
    "                    chunk = chunk.to(computing_device)\n",
    "                    targets = targets.to(computing_device)\n",
    "\n",
    "                    # Forward pass\n",
    "                    output, hidden = model(chunk, hidden)\n",
    "\n",
    "                    # Compute loss\n",
    "                    targets = targets.argmax(dim=1)\n",
    "                    loss = criterion(output, targets)\n",
    "                    song_loss += loss\n",
    "\n",
    "                    # Backwards pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Detach hidden state from LSTM for next TBPTT chunk\n",
    "                    hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "                total_loss += song_loss / num_minibatches\n",
    "            '''\n",
    "            average_epoch_loss = total_loss / len(train_songs)\n",
    "            print(f\"Epoch {str(epoch + 1)} with training error {str(average_epoch_loss.cpu().item())}\")\n",
    "\n",
    "            \n",
    "            \n",
    "            total_loss = 0\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for song in val_songs:\n",
    "                    # Set states to 0 at the beginning of each song\n",
    "                    hidden_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "                    hidden_state = hidden_state.float()\n",
    "                    cell_state = torch.zeros((config['num_layers'], 1, config['num_neurons'])).to(computing_device)\n",
    "                    cell_state = cell_state.float()\n",
    "                    hidden = (hidden_state, cell_state)\n",
    "\n",
    "                    song_loss = 0\n",
    "\n",
    "                    # Encode the characters to their respective one hot encoding\n",
    "                    dataset = MyDataset(song, config['chunk_length'])\n",
    "                    num_minibatches = len(dataset)\n",
    "                    for i in range(num_minibatches):\n",
    "                        chunk, targets = dataset[i]\n",
    "                        if len(chunk) == 0:\n",
    "                            break\n",
    "\n",
    "                        # Send minibatch to computing device\n",
    "                        chunk = chunk.to(computing_device)\n",
    "                        targets = targets.to(computing_device)\n",
    "\n",
    "                        # Forward pass\n",
    "                        output, hidden = model(chunk, hidden)\n",
    "\n",
    "                        # Compute loss\n",
    "                        targets = targets.argmax(dim=1)\n",
    "                        loss = criterion(output, targets)\n",
    "                        song_loss += loss\n",
    "\n",
    "                    total_loss += song_loss / num_minibatches\n",
    "\n",
    "            average_val_epoch_loss = total_loss / len(val_songs)\n",
    "            print(f\"Epoch {str(epoch + 1)} with validation error {str(average_val_epoch_loss.cpu().item())}\")\n",
    "\n",
    "        x.to(device)\n",
    "        encoder_output = self.encoder(x)  # output of convolutional network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
